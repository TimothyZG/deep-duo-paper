training:
  batch_size: 32
  num_epochs_lp: 5
  num_epochs_ff: 10
  num_workers: 4